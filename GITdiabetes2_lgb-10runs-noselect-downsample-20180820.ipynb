{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# from sklearn.metrics import log_loss  \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold  ,train_test_split   \n",
    "# from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import scipy.io\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "from scipy import stats\n",
    "import copy\n",
    "# d = { ... }\n",
    "# d2 = copy.deepcopy(d)\n",
    "\n",
    "tic=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1286,)\n"
     ]
    }
   ],
   "source": [
    "name=pd.read_csv('name.csv')\n",
    "name=name.iloc[0]#name.T\n",
    "print(name.values.shape)\n",
    "\n",
    "# data=load('data_26478_1286.mat','extended_allFeas','labels','name');\n",
    "mat =scipy.io.loadmat('data_26478_1286.mat')\n",
    "# X=mat['extended_allFeas']\n",
    "y=mat['labels']-1\n",
    "df_new=pd.DataFrame(mat['extended_allFeas'], columns=name.values)\n",
    "# df_new.describe()\n",
    "\n",
    "df_new['y']=y\n",
    "\n",
    "df = df_new.loc[:, df_new.std()>0.01].copy()\n",
    "print(df.shape)\n",
    "\n",
    "## feature selection\n",
    "# df0=df[df['y']==0]\n",
    "# df1=df[df['y']==1]\n",
    "# p_v=np.zeros(len(df.columns))\n",
    "# for i in range(len(df.columns)):\n",
    "#     col=df.columns[i]\n",
    "#     p_v[i]=stats.ttest_ind(df0[col], df1[col], equal_var = False).pvalue\n",
    "\n",
    "# df_pv = pd.DataFrame({'columns':df.columns, 'p_v':p_v})\n",
    "# # df_pv.sort_values(by='p_v')\n",
    "\n",
    "# drop_col=df_pv[df_pv['p_v']>0.05]['columns']\n",
    "# df.drop(df.columns[df.columns.isin(drop_col)].values, inplace=True, axis=1)\n",
    "# print(df.shape)\n",
    "\n",
    "name=df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_subsample(x,y,subsample_size=1.0):\n",
    "    np.random.seed(2018)\n",
    "    class_xs = []\n",
    "    min_elems = None\n",
    "\n",
    "    for yi in np.unique(y):\n",
    "        elems = x[(y == yi)]\n",
    "        class_xs.append((yi, elems))\n",
    "        if min_elems == None or elems.shape[0] < min_elems:\n",
    "            min_elems = elems.shape[0]\n",
    "\n",
    "    use_elems = min_elems\n",
    "    if subsample_size < 1:\n",
    "        use_elems = int(min_elems*subsample_size)\n",
    "\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for ci,this_xs in class_xs:\n",
    "        if len(this_xs) > use_elems:\n",
    "            np.random.shuffle(this_xs)\n",
    "\n",
    "        x_ = this_xs[:use_elems]\n",
    "        y_ = np.empty(use_elems)\n",
    "        y_.fill(ci)\n",
    "\n",
    "        xs.append(x_)\n",
    "        ys.append(y_)\n",
    "\n",
    "    xs = np.concatenate(xs)\n",
    "    ys = np.concatenate(ys)\n",
    "\n",
    "    return xs,ys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgb\n",
    "\n",
    "https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "\n",
    "To get good results using a leaf-wise tree, these are some important parameters:\n",
    "\n",
    "    num_leaves. This is the main parameter to control the complexity of the tree model. Theoretically, we can set num_leaves = 2^(max_depth) to obtain the same number of leaves as depth-wise tree. However, this simple conversion is not good in practice. The reason is that a leaf-wise tree is typically much deeper than a depth-wise tree for a fixed number of leaves. Unconstrained depth can induce over-fitting. Thus, when trying to tune the num_leaves, we should let it be smaller than 2^(max_depth). For example, when the max_depth=7 the depth-wise tree can get good accuracy, but setting num_leaves to 127 may cause over-fitting, and setting it to 70 or 80 may get better accuracy than depth-wise.\n",
    "    min_data_in_leaf. This is a very important parameter to prevent over-fitting in a leaf-wise tree. Its optimal value depends on the number of training samples and num_leaves. Setting it to a large value can avoid growing too deep a tree, but may cause under-fitting. In practice, setting it to hundreds or thousands is enough for a large dataset.\n",
    "    max_depth. You also can use max_depth to limit the tree depth explicitly.\n",
    "\n",
    "For Faster Speed\n",
    "\n",
    "    Use bagging by setting bagging_fraction and bagging_freq\n",
    "    Use feature sub-sampling by setting feature_fraction\n",
    "    Use small max_bin\n",
    "    Use save_binary to speed up data loading in future learning\n",
    "    Use parallel learning, refer to Parallel Learning Guide\n",
    "\n",
    "For Better Accuracy\n",
    "\n",
    "    Use large max_bin (may be slower)\n",
    "    Use small learning_rate with large num_iterations\n",
    "    Use large num_leaves (may cause over-fitting)\n",
    "    Use bigger training data\n",
    "    Try dart\n",
    "\n",
    "Deal with Over-fitting\n",
    "\n",
    "    Use small max_bin\n",
    "    Use small num_leaves\n",
    "    Use min_data_in_leaf and min_sum_hessian_in_leaf\n",
    "    Use bagging by set bagging_fraction and bagging_freq\n",
    "    Use feature sub-sampling by set feature_fraction\n",
    "    Use bigger training data\n",
    "    Try lambda_l1, lambda_l2 and min_gain_to_split for regularization\n",
    "    Try max_depth to avoid growing deep tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "score10=[]\n",
    "num_round = 1000\n",
    "\n",
    "ytest10 = np.zeros((round(df.shape[0]*0.6), 10))#pd.DataFrame()\n",
    "lgb_preds10 = np.zeros((round(df.shape[0]*0.6), 10))#pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for seed in np.array(range(0,10,1)):\n",
    "    X=df.drop('y', axis=1).values\n",
    "    X_train, xtest, y_train, ytest = train_test_split(X, y,stratify=y, test_size=0.6,  random_state=seed)\n",
    "    xtrain, xvalid, ytrain, yvalid = train_test_split(X_train, y_train,stratify=y_train, test_size=0.3,  random_state=seed)\n",
    "    xtrain, ytrain=balanced_subsample(xtrain, ytrain.ravel(),subsample_size=1.0)\n",
    "    xvalid, yvalid=balanced_subsample(xvalid, yvalid.ravel(),subsample_size=1.0)\n",
    "    print(xtrain.shape, xvalid.shape)\n",
    "    dtrain = lgb.Dataset(xtrain,  ytrain.ravel(),  free_raw_data=False)#lgb.Dataset(X,  y, free_raw_data=False)\n",
    "    dval = lgb.Dataset(xvalid, yvalid.ravel(),reference=dtrain, free_raw_data=False)\n",
    "\n",
    "    best_score=0.5\n",
    "    for i in np.array(range(80,141,10)):#\n",
    "        np.random.seed(i)#+1000 \n",
    "        params = {\n",
    "            'learning_rate': [0.05],\n",
    "            'boosting_type' : ['gbdt'],\n",
    "            'objective' : ['binary'],#'regression',#\n",
    "            \"feature_fraction\":0.6,\n",
    "            'bagging_fraction' : .8,\n",
    "            'metric': 'auc',#'rmse',#'RMSE',#'rmsle',\n",
    "            'seed': np.random.randint(1,10000),#i,\n",
    "            'silent': True#,\n",
    "        }    \n",
    "        params['nthread'] =9# 16#28#16#\n",
    "        params['num_leaves'] = i#\n",
    "\n",
    "        bst = lgb.train(params, dtrain, num_round, valid_sets=dval,verbose_eval=500,early_stopping_rounds=50,feature_name=list(df.drop('y', axis=1).columns))#, feval=rmsle  valid_sets=[dtrain, dval], ,categorical_feature=list(cat_col)\n",
    "        lgb_preds = bst.predict(xvalid, num_iteration=bst.best_iteration)\n",
    "        fpr, tpr, thresholds = roc_curve(yvalid, lgb_preds)\n",
    "        score1 =  auc(fpr, tpr)\n",
    "        if score1 > best_score:#0.9:#\n",
    "            best_score=score1\n",
    "            best_params=copy.deepcopy(params)\n",
    "            best_nround=bst.best_iteration#\n",
    "\n",
    "    print(best_score,best_nround)\n",
    "    print(best_params['num_leaves']) \n",
    "    ##########################################\n",
    "    params = copy.deepcopy(best_params)#\n",
    "    best_score=0.5\n",
    "    for j in np.array(range(14,26,2)):\n",
    "        np.random.seed(j)#+1000 \n",
    "        params['min_data_in_leaf'] = j\n",
    "        bst = lgb.train(params, dtrain, num_round, valid_sets=dval,verbose_eval=500,early_stopping_rounds=50,feature_name=list(df.drop('y', axis=1).columns))#, feval=rmsle  valid_sets=[dtrain, dval], ,categorical_feature=list(cat_col)\n",
    "        lgb_preds = bst.predict(xvalid, num_iteration=bst.best_iteration)\n",
    "        fpr, tpr, thresholds = roc_curve(yvalid, lgb_preds)\n",
    "        score1 =  auc(fpr, tpr)\n",
    "        if score1 > best_score:#0.9:#\n",
    "            best_score=score1\n",
    "            best_params=copy.deepcopy(params)\n",
    "            best_nround=bst.best_iteration#score.iloc[:,0].idxmin()\n",
    "\n",
    "    print(best_score,best_nround)\n",
    "    print(best_params['min_data_in_leaf']) \n",
    "\n",
    "    best_score=0.5\n",
    "    for j in np.array(range(1,10,1)):\n",
    "        np.random.seed(j)#+1000 \n",
    "        params =  copy.deepcopy(params)#best_params\n",
    "        params['learparams =ning_rate'] = 0.01*j,\n",
    "        bst = lgb.train(params, dtrain, num_round, valid_sets=dval,verbose_eval=500,early_stopping_rounds=50,feature_name=list(df.drop('y', axis=1).columns))#, feval=rmsle  valid_sets=[dtrain, dval], ,categorical_feature=list(cat_col)\n",
    "        lgb_preds = bst.predict(xvalid, num_iteration=bst.best_iteration)\n",
    "        fpr, tpr, thresholds = roc_curve(yvalid, lgb_preds)\n",
    "        score1 =  auc(fpr, tpr)\n",
    "        if score1 > best_score:#0.9:#\n",
    "            best_score=score1\n",
    "            best_params=copy.deepcopy(params)\n",
    "            best_nround=bst.best_iteration#score.iloc[:,0].idxmin()\n",
    "\n",
    "    print(best_score,best_nround)\n",
    "    print(best_params) \n",
    "\n",
    "    bst = lgb.train(best_params, lgb.Dataset(np.vstack((xtrain, xvalid)), np.hstack((ytrain.ravel(), yvalid.ravel())), free_raw_data=False), best_nround, valid_sets=dval,verbose_eval=500,early_stopping_rounds=50,feature_name=list(df.drop('y', axis=1).columns))#,categorical_feature=list(cat_col) \n",
    "    #,categorical_feature=list(cat_col)\n",
    "    lgb_preds = bst.predict(xtest, num_iteration=bst.best_iteration)\n",
    "    ytest10[:,seed], lgb_preds10[:,seed]=ytest.ravel(), lgb_preds.ravel()\n",
    "    fpr, tpr, thresholds = roc_curve(ytest, lgb_preds)\n",
    "    score1 =  auc(fpr, tpr)\n",
    "    print(score1)\n",
    "    score10.append(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.114830</td>\n",
       "      <td>0.108171</td>\n",
       "      <td>0.920243</td>\n",
       "      <td>0.087780</td>\n",
       "      <td>0.098157</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>0.024754</td>\n",
       "      <td>0.136849</td>\n",
       "      <td>0.996356</td>\n",
       "      <td>0.016641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134110</td>\n",
       "      <td>0.022859</td>\n",
       "      <td>0.037195</td>\n",
       "      <td>0.129907</td>\n",
       "      <td>0.992219</td>\n",
       "      <td>0.970987</td>\n",
       "      <td>0.042750</td>\n",
       "      <td>0.013869</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>0.024103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038738</td>\n",
       "      <td>0.041355</td>\n",
       "      <td>0.387569</td>\n",
       "      <td>0.052367</td>\n",
       "      <td>0.981490</td>\n",
       "      <td>0.869370</td>\n",
       "      <td>0.032246</td>\n",
       "      <td>0.984800</td>\n",
       "      <td>0.343327</td>\n",
       "      <td>0.005513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.079538</td>\n",
       "      <td>0.968849</td>\n",
       "      <td>0.311646</td>\n",
       "      <td>0.996030</td>\n",
       "      <td>0.058602</td>\n",
       "      <td>0.395917</td>\n",
       "      <td>0.031288</td>\n",
       "      <td>0.972688</td>\n",
       "      <td>0.785102</td>\n",
       "      <td>0.033118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.351195</td>\n",
       "      <td>0.024270</td>\n",
       "      <td>0.640224</td>\n",
       "      <td>0.860778</td>\n",
       "      <td>0.142378</td>\n",
       "      <td>0.972494</td>\n",
       "      <td>0.138221</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.082207</td>\n",
       "      <td>0.345042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.114830  0.108171  0.920243  0.087780  0.098157  0.011428  0.024754   \n",
       "1  0.134110  0.022859  0.037195  0.129907  0.992219  0.970987  0.042750   \n",
       "2  0.038738  0.041355  0.387569  0.052367  0.981490  0.869370  0.032246   \n",
       "3  0.079538  0.968849  0.311646  0.996030  0.058602  0.395917  0.031288   \n",
       "4  0.351195  0.024270  0.640224  0.860778  0.142378  0.972494  0.138221   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.136849  0.996356  0.016641  \n",
       "1  0.013869  0.009141  0.024103  \n",
       "2  0.984800  0.343327  0.005513  \n",
       "3  0.972688  0.785102  0.033118  \n",
       "4  0.003710  0.082207  0.345042  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ytest10 = pd.DataFrame(ytest10)\n",
    "df_lgb_preds10 = pd.DataFrame(lgb_preds10)\n",
    "df_lgb_preds10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ytest10.to_csv('df_ytest10',  index=False)#encoding='utf-8',\n",
    "df_lgb_preds10.to_csv('df_lgb_preds10',  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2856, 1264), (2856,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((xtrain, xvalid)).shape, np.hstack((ytrain.ravel(), yvalid.ravel())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1348314606741573, 0.5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean(),ytrain.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.91277422330639546,\n",
       " 0.91835126193074534,\n",
       " 0.91777836877445296,\n",
       " 0.92211035742052361,\n",
       " 0.91818367701148595,\n",
       " 0.91956827353228188,\n",
       " 0.91559370201336265,\n",
       " 0.92219365738292403,\n",
       " 0.92506213107287294,\n",
       " 0.91853769760602211]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores10=np.array(score10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.91901533500510657, 0.0033181365125995654)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores10.mean(),scores10.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 14))\n",
    "lgb.plot_importance(bst, max_num_features=60, ax=ax)\n",
    "plt.title(\"Light GBM Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487.76337575912476"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()-tic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
